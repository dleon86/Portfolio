{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NLP Article summarization\n",
    "In this notebook, I used the Beautiful Soup package to extract the text from a web article. Then I used the NLTK and textblob libraries to preprocess the text by removing words that don't contribute much to the overall interpretation of the text, as well as applying a lemma-ization process to simplify words to their rawest meaning. Then, I chunked up the text into batch sizes that were then fed through the Hugging Face Text-Summarization library. Lastly, I re-ran the initial summary through the pipeline a second time which allowed for an even more condensed summary.\n",
    "\n",
    "This article was not chosen for any special content, but for the simplicity of the html formatting, which allowed for  the easy text extraction. This process could be automated and scheduled to summarize articles and store them for later reading.\n",
    "\n",
    "One thing I am considering for future work on this is to add Text to Speech pipeline to read the summaries out loud. Another future project will be scheduling a scraping event (something like headlines only), and running sentiment analysis on those."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Importing Packages\n",
    "- We use the requests module to get the source html data of the web article\n",
    "- We will import the Beautiful Soup library to parse the scraped web data\n",
    "- We will import the HuggingFace Transformers package and use the summarization pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 (https://huggingface.co/sshleifer/distilbart-cnn-12-6)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Choose the html for the article\n",
    "We are choosing an arbitrary article on www.hackernoon.com because it's webpages are simple compared to others"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# URL = \"https://hackernoon.com/will-layer-1-public-blockchains-rise-or-fall-in-the-next-bull-market\"\n",
    "URL = \"https://hackernoon.com/how-to-manage-your-technology-and-reduce-your-digital-distractions\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Set up useful functions for task\n",
    "Using Beautiful Soup, parse the html data and break text into sentence blocks. then run the sentence blocks through the summarization pipeline."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def bsArticle(url):\n",
    "    # This function takes url's for articles from webpages with simple structure and outputs the sentences tagged\n",
    "    # with <eos> tags\n",
    "    a = requests.get(URL)\n",
    "    soup = BeautifulSoup(a.text, 'html.parser')\n",
    "    results = soup.find_all(['h1', 'h2', 'h3', 'p'])\n",
    "    text = [result.text for result in results]\n",
    "    article = ''.join(text)\n",
    "    article = preprocess_article(article)\n",
    "    sentences = add_eos(article)\n",
    "    return block_sentences(sentences)\n",
    "\n",
    "\n",
    "def add_eos(raw_article):\n",
    "    # add end-of-sentence markers\n",
    "    raw_article = raw_article.replace('.', '.<eos>')\n",
    "    raw_article = raw_article.replace('?', '?<eos>')\n",
    "    raw_article = raw_article.replace('!', '!<eos>')\n",
    "    return split_sentences(raw_article)\n",
    "\n",
    "\n",
    "def split_sentences(raw_article):\n",
    "    # function for splitting a string element comprised of multiple sentences into individual sentences\n",
    "    return raw_article.split('<eos>')\n",
    "\n",
    "\n",
    "def block_sentences(sentences, max_block_size=2 ** 8):\n",
    "    # this function puts the sentences into blocks up to a max_block_size\n",
    "    blocks = []\n",
    "    i = 0\n",
    "\n",
    "    for sentence in sentences:\n",
    "        # check if there is an existing block: Y, append; N, start new block\n",
    "        if len(blocks) == i + 1:\n",
    "            if len(blocks[i]) + len(sentence.split(' ')) <= max_block_size:\n",
    "                blocks[i].extend(sentence.split(' '))\n",
    "            else:\n",
    "                i += 1\n",
    "                blocks.append(sentence.split(' '))\n",
    "        else:\n",
    "            blocks.append(sentence.split(' '))\n",
    "\n",
    "    for i in range(len(blocks)):\n",
    "        blocks[i] = ' '.join(blocks[i])\n",
    "\n",
    "    return blocks\n",
    "\n",
    "\n",
    "def summarize(URL):\n",
    "    #\n",
    "    blocks = bsArticle(URL)\n",
    "    print(f'Number of blocks of text: {len(blocks)}')\n",
    "    return summarizer(blocks, min_length=16, max_length=128, do_sample=False)\n",
    "\n",
    "def reSummarize(summary):\n",
    "    # This function takes as input, a summary that was already generated and re-runs it through the pipeline for a\n",
    "    # more condensed summary\n",
    "    text = [sentence['summary_text'] for sentence in summary]\n",
    "    article = ''.join(text)\n",
    "    article = preprocess_article(article)\n",
    "    sentences = add_eos(article)\n",
    "    blocks = block_sentences(sentences, max_block_size=256)\n",
    "    print(f'Number of blocks of text: {len(blocks)}')\n",
    "    summary = summarizer(blocks, min_length=16, max_length=128, do_sample=False)\n",
    "    return summary\n",
    "\n",
    "\n",
    "def readSummary(summary):\n",
    "    print('Primary Summary :', ''.join([sm['summary_text'] for sm in summary]))\n",
    "\n",
    "\n",
    "def writeSummary(text, title='articleSummary'):\n",
    "    with open(title + '.txt', 'w', encoding='utf-32') as f:\n",
    "        f.write(''.join([sm['summary_text'] for sm in text]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import nltk and textblob libraries for cleaning data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\danny\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\danny\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\danny\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "# !pip install textblob\n",
    "from textblob import Word\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "stop_words = stopwords.words('english')\n",
    "# custom_stopwords = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def preprocess_article(article):  # , custom_stopwords):\n",
    "    processed_article = article\n",
    "    processed_article.replace('[^\\w\\s]', '')\n",
    "    processed_article = \" \".join(word for word in processed_article.split() if word not in stop_words)\n",
    "    # processed_article = \" \".join(word for word in processed_article.split() if word not in custom_stopwords)\n",
    "    processed_article = \" \".join(Word(word).lemmatize() for word in processed_article.split())\n",
    "    return(processed_article)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Summarize the article"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of blocks of text: 5\n",
      "Primary Summary :  As world becomes connected people, businesses, thing connected time, it’s become increasingly important find way manage technology order reduce digital distractions . A digital distraction non-essential technology use take attention away need given moment time . Research found average person spends nearly half daily time awake either looking phone thinking it. Diversion Is Important So You Don’t Feel Overwhelmed . Turn off Your Automatic Response Feature Your Email . Take regular tech breaks and set timer remind need take break . Social Media Anxiety Disorder may indicate real condition called Social Media anxiety Disorder . Social medium usage causes psychological problems, including anxiety, depression, loneliness, loneliness . Technology negative impact physical health addition damaging real-world relationships . Technology fantastic form distraction provide comfortable distraction mental health issues . If you’re online time, it’s likely you're missing many aspect life could help you . Depression is common trait among depression . Social pressure is likely to lead to low self-esteem . It’s important remember technology isn’t bad – useful tool managing mental health boosting self-esteem . Social medium excellent platform making new friend gaining inspiration . But remember people rarely showing true self social medium – they’re likely projecting positive image .\n"
     ]
    }
   ],
   "source": [
    "summary = summarize(URL)\n",
    "readSummary(summary)\n",
    "writeSummary(summary, 'articlePrimarySummary_wPreprocessing')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Resummarize the summary\n",
    "Try to summarize the summary for a more compressed total summary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of blocks of text: 1\n",
      "Primary Summary :  As world becomes connected people, businesses, thing connected time, it’s become increasingly important find way manage technology order reduce digital distraction . Social medium usage cause psychological problems, including anxiety, depression, loneliness, loneliness . Technology negative impact physical health addition damaging real-world relationship . Diversion Is Important So You Don’t Feel Overwhelmed .\n"
     ]
    }
   ],
   "source": [
    "summary2 = reSummarize(summary)\n",
    "readSummary(summary2)\n",
    "writeSummary(summary2, 'articleSecondarySummary_wPreprocessing')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}